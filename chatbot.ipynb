{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\woongbin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\woongbin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\woongbin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas) (1.24.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\woongbin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\woongbin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting sentence_transformers\n",
      "  Using cached sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\woongbin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from sentence_transformers) (4.25.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\woongbin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from sentence_transformers) (4.64.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\woongbin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from sentence_transformers) (1.13.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\woongbin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from sentence_transformers) (0.14.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\woongbin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from sentence_transformers) (1.24.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\woongbin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from sentence_transformers) (1.2.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\woongbin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from sentence_transformers) (1.9.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\woongbin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from sentence_transformers) (3.8)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\woongbin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from sentence_transformers) (0.1.97)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\woongbin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from sentence_transformers) (0.11.1)\n",
      "Requirement already satisfied: requests in c:\\users\\woongbin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\woongbin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (22.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\woongbin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\woongbin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.8.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\woongbin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\woongbin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.10.31)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\woongbin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\woongbin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tqdm->sentence_transformers) (0.4.6)\n",
      "Requirement already satisfied: joblib in c:\\users\\woongbin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk->sentence_transformers) (1.2.0)\n",
      "Requirement already satisfied: click in c:\\users\\woongbin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk->sentence_transformers) (8.1.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\woongbin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\woongbin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torchvision->sentence_transformers) (9.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\woongbin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\woongbin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\woongbin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\woongbin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.13)\n",
      "Installing collected packages: sentence_transformers\n",
      "  Running setup.py install for sentence_transformers: started\n",
      "  Running setup.py install for sentence_transformers: finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: sentence_transformers is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Running setup.py install for sentence_transformers did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [97 lines of output]\n",
      "      C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2544.0_x64__qbz5n2kfra8p0\\lib\\site-packages\\setuptools\\dist.py:771: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
      "        warnings.warn(\n",
      "      running install\n",
      "      C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2544.0_x64__qbz5n2kfra8p0\\lib\\site-packages\\setuptools\\command\\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "        warnings.warn(\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\n",
      "      creating build\\lib\n",
      "      creating build\\lib\\sentence_transformers\n",
      "      copying sentence_transformers\\LoggingHandler.py -> build\\lib\\sentence_transformers\n",
      "      copying sentence_transformers\\model_card_templates.py -> build\\lib\\sentence_transformers\n",
      "      copying sentence_transformers\\SentenceTransformer.py -> build\\lib\\sentence_transformers\n",
      "      copying sentence_transformers\\util.py -> build\\lib\\sentence_transformers\n",
      "      copying sentence_transformers\\__init__.py -> build\\lib\\sentence_transformers\n",
      "      creating build\\lib\\sentence_transformers\\cross_encoder\n",
      "      copying sentence_transformers\\cross_encoder\\CrossEncoder.py -> build\\lib\\sentence_transformers\\cross_encoder\n",
      "      copying sentence_transformers\\cross_encoder\\__init__.py -> build\\lib\\sentence_transformers\\cross_encoder\n",
      "      creating build\\lib\\sentence_transformers\\datasets\n",
      "      copying sentence_transformers\\datasets\\DenoisingAutoEncoderDataset.py -> build\\lib\\sentence_transformers\\datasets\n",
      "      copying sentence_transformers\\datasets\\NoDuplicatesDataLoader.py -> build\\lib\\sentence_transformers\\datasets\n",
      "      copying sentence_transformers\\datasets\\ParallelSentencesDataset.py -> build\\lib\\sentence_transformers\\datasets\n",
      "      copying sentence_transformers\\datasets\\SentenceLabelDataset.py -> build\\lib\\sentence_transformers\\datasets\n",
      "      copying sentence_transformers\\datasets\\SentencesDataset.py -> build\\lib\\sentence_transformers\\datasets\n",
      "      copying sentence_transformers\\datasets\\__init__.py -> build\\lib\\sentence_transformers\\datasets\n",
      "      creating build\\lib\\sentence_transformers\\evaluation\n",
      "      copying sentence_transformers\\evaluation\\BinaryClassificationEvaluator.py -> build\\lib\\sentence_transformers\\evaluation\n",
      "      copying sentence_transformers\\evaluation\\EmbeddingSimilarityEvaluator.py -> build\\lib\\sentence_transformers\\evaluation\n",
      "      copying sentence_transformers\\evaluation\\InformationRetrievalEvaluator.py -> build\\lib\\sentence_transformers\\evaluation\n",
      "      copying sentence_transformers\\evaluation\\LabelAccuracyEvaluator.py -> build\\lib\\sentence_transformers\\evaluation\n",
      "      copying sentence_transformers\\evaluation\\MSEEvaluator.py -> build\\lib\\sentence_transformers\\evaluation\n",
      "      copying sentence_transformers\\evaluation\\MSEEvaluatorFromDataFrame.py -> build\\lib\\sentence_transformers\\evaluation\n",
      "      copying sentence_transformers\\evaluation\\ParaphraseMiningEvaluator.py -> build\\lib\\sentence_transformers\\evaluation\n",
      "      copying sentence_transformers\\evaluation\\RerankingEvaluator.py -> build\\lib\\sentence_transformers\\evaluation\n",
      "      copying sentence_transformers\\evaluation\\SentenceEvaluator.py -> build\\lib\\sentence_transformers\\evaluation\n",
      "      copying sentence_transformers\\evaluation\\SequentialEvaluator.py -> build\\lib\\sentence_transformers\\evaluation\n",
      "      copying sentence_transformers\\evaluation\\SimilarityFunction.py -> build\\lib\\sentence_transformers\\evaluation\n",
      "      copying sentence_transformers\\evaluation\\TranslationEvaluator.py -> build\\lib\\sentence_transformers\\evaluation\n",
      "      copying sentence_transformers\\evaluation\\TripletEvaluator.py -> build\\lib\\sentence_transformers\\evaluation\n",
      "      copying sentence_transformers\\evaluation\\__init__.py -> build\\lib\\sentence_transformers\\evaluation\n",
      "      creating build\\lib\\sentence_transformers\\losses\n",
      "      copying sentence_transformers\\losses\\BatchAllTripletLoss.py -> build\\lib\\sentence_transformers\\losses\n",
      "      copying sentence_transformers\\losses\\BatchHardSoftMarginTripletLoss.py -> build\\lib\\sentence_transformers\\losses\n",
      "      copying sentence_transformers\\losses\\BatchHardTripletLoss.py -> build\\lib\\sentence_transformers\\losses\n",
      "      copying sentence_transformers\\losses\\BatchSemiHardTripletLoss.py -> build\\lib\\sentence_transformers\\losses\n",
      "      copying sentence_transformers\\losses\\ContrastiveLoss.py -> build\\lib\\sentence_transformers\\losses\n",
      "      copying sentence_transformers\\losses\\ContrastiveTensionLoss.py -> build\\lib\\sentence_transformers\\losses\n",
      "      copying sentence_transformers\\losses\\CosineSimilarityLoss.py -> build\\lib\\sentence_transformers\\losses\n",
      "      copying sentence_transformers\\losses\\DenoisingAutoEncoderLoss.py -> build\\lib\\sentence_transformers\\losses\n",
      "      copying sentence_transformers\\losses\\MarginMSELoss.py -> build\\lib\\sentence_transformers\\losses\n",
      "      copying sentence_transformers\\losses\\MegaBatchMarginLoss.py -> build\\lib\\sentence_transformers\\losses\n",
      "      copying sentence_transformers\\losses\\MSELoss.py -> build\\lib\\sentence_transformers\\losses\n",
      "      copying sentence_transformers\\losses\\MultipleNegativesRankingLoss.py -> build\\lib\\sentence_transformers\\losses\n",
      "      copying sentence_transformers\\losses\\MultipleNegativesSymmetricRankingLoss.py -> build\\lib\\sentence_transformers\\losses\n",
      "      copying sentence_transformers\\losses\\OnlineContrastiveLoss.py -> build\\lib\\sentence_transformers\\losses\n",
      "      copying sentence_transformers\\losses\\SoftmaxLoss.py -> build\\lib\\sentence_transformers\\losses\n",
      "      copying sentence_transformers\\losses\\TripletLoss.py -> build\\lib\\sentence_transformers\\losses\n",
      "      copying sentence_transformers\\losses\\__init__.py -> build\\lib\\sentence_transformers\\losses\n",
      "      creating build\\lib\\sentence_transformers\\models\n",
      "      copying sentence_transformers\\models\\Asym.py -> build\\lib\\sentence_transformers\\models\n",
      "      copying sentence_transformers\\models\\BoW.py -> build\\lib\\sentence_transformers\\models\n",
      "      copying sentence_transformers\\models\\CLIPModel.py -> build\\lib\\sentence_transformers\\models\n",
      "      copying sentence_transformers\\models\\CNN.py -> build\\lib\\sentence_transformers\\models\n",
      "      copying sentence_transformers\\models\\Dense.py -> build\\lib\\sentence_transformers\\models\n",
      "      copying sentence_transformers\\models\\Dropout.py -> build\\lib\\sentence_transformers\\models\n",
      "      copying sentence_transformers\\models\\LayerNorm.py -> build\\lib\\sentence_transformers\\models\n",
      "      copying sentence_transformers\\models\\LSTM.py -> build\\lib\\sentence_transformers\\models\n",
      "      copying sentence_transformers\\models\\Normalize.py -> build\\lib\\sentence_transformers\\models\n",
      "      copying sentence_transformers\\models\\Pooling.py -> build\\lib\\sentence_transformers\\models\n",
      "      copying sentence_transformers\\models\\Transformer.py -> build\\lib\\sentence_transformers\\models\n",
      "      copying sentence_transformers\\models\\WeightedLayerPooling.py -> build\\lib\\sentence_transformers\\models\n",
      "      copying sentence_transformers\\models\\WordEmbeddings.py -> build\\lib\\sentence_transformers\\models\n",
      "      copying sentence_transformers\\models\\WordWeights.py -> build\\lib\\sentence_transformers\\models\n",
      "      copying sentence_transformers\\models\\__init__.py -> build\\lib\\sentence_transformers\\models\n",
      "      creating build\\lib\\sentence_transformers\\readers\n",
      "      copying sentence_transformers\\readers\\InputExample.py -> build\\lib\\sentence_transformers\\readers\n",
      "      copying sentence_transformers\\readers\\LabelSentenceReader.py -> build\\lib\\sentence_transformers\\readers\n",
      "      copying sentence_transformers\\readers\\NLIDataReader.py -> build\\lib\\sentence_transformers\\readers\n",
      "      copying sentence_transformers\\readers\\PairedFilesReader.py -> build\\lib\\sentence_transformers\\readers\n",
      "      copying sentence_transformers\\readers\\STSDataReader.py -> build\\lib\\sentence_transformers\\readers\n",
      "      copying sentence_transformers\\readers\\TripletReader.py -> build\\lib\\sentence_transformers\\readers\n",
      "      copying sentence_transformers\\readers\\__init__.py -> build\\lib\\sentence_transformers\\readers\n",
      "      creating build\\lib\\sentence_transformers\\cross_encoder\\evaluation\n",
      "      copying sentence_transformers\\cross_encoder\\evaluation\\CEBinaryAccuracyEvaluator.py -> build\\lib\\sentence_transformers\\cross_encoder\\evaluation\n",
      "      copying sentence_transformers\\cross_encoder\\evaluation\\CEBinaryClassificationEvaluator.py -> build\\lib\\sentence_transformers\\cross_encoder\\evaluation\n",
      "      copying sentence_transformers\\cross_encoder\\evaluation\\CECorrelationEvaluator.py -> build\\lib\\sentence_transformers\\cross_encoder\\evaluation\n",
      "      copying sentence_transformers\\cross_encoder\\evaluation\\CERerankingEvaluator.py -> build\\lib\\sentence_transformers\\cross_encoder\\evaluation\n",
      "      copying sentence_transformers\\cross_encoder\\evaluation\\CESoftmaxAccuracyEvaluator.py -> build\\lib\\sentence_transformers\\cross_encoder\\evaluation\n",
      "      copying sentence_transformers\\cross_encoder\\evaluation\\__init__.py -> build\\lib\\sentence_transformers\\cross_encoder\\evaluation\n",
      "      creating build\\lib\\sentence_transformers\\models\\tokenizer\n",
      "      copying sentence_transformers\\models\\tokenizer\\PhraseTokenizer.py -> build\\lib\\sentence_transformers\\models\\tokenizer\n",
      "      copying sentence_transformers\\models\\tokenizer\\WhitespaceTokenizer.py -> build\\lib\\sentence_transformers\\models\\tokenizer\n",
      "      copying sentence_transformers\\models\\tokenizer\\WordTokenizer.py -> build\\lib\\sentence_transformers\\models\\tokenizer\n",
      "      copying sentence_transformers\\models\\tokenizer\\__init__.py -> build\\lib\\sentence_transformers\\models\\tokenizer\n",
      "      running install_lib\n",
      "      byte-compiling C:\\Users\\Woongbin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sentence_transformers\\cross_encoder\\evaluation\\CEBinaryClassificationEvaluator.py to CEBinaryClassificationEvaluator.cpython-310.pyc\n",
      "      error: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Woongbin\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python310\\\\site-packages\\\\sentence_transformers\\\\cross_encoder\\\\evaluation\\\\__pycache__\\\\CEBinaryClassificationEvaluator.cpython-310.pyc.2460153684944'\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: legacy-install-failure\n",
      "\n",
      "× Encountered error while trying to install package.\n",
      "╰─> sentence_transformers\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for output from the failure.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\users\\woongbin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.0.post1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install sentence_transformers\n",
    "%pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.10478326 -0.1916139   0.03850413 ...  0.60394865  0.5057753\n",
      "  -0.73618925]\n",
      " [ 0.10453978  0.1911693  -0.916104   ... -0.16573744  0.20779406\n",
      "  -0.34834778]]\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"jhgan/ko-sroberta-multitask\")\n",
    "sentences = ['학교가 어디인가요?', '저는 부산 소마고에 다니고 있습니다.']\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>구분</th>\n",
       "      <th>유저</th>\n",
       "      <th>챗봇</th>\n",
       "      <th>embedding</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>입학홍보</td>\n",
       "      <td>부산소마고는 어떤 곳인가요?</td>\n",
       "      <td>저희 부산소프트웨어마이스터고등학교를 소개합니다. 저희 학교는 4차산업 중심 교육으로...</td>\n",
       "      <td>[-0.06551128, -0.048543196, -0.2451021, 0.4099...</td>\n",
       "      <td>0.628634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>질의응답</td>\n",
       "      <td>학교 기숙사는 어떤가요?</td>\n",
       "      <td>저희 학교 기숙사는 깨끗하고 좋습니다. 2인 1실에 각자 침대와 책상이 있구요. 기...</td>\n",
       "      <td>[-0.12231439, -0.43419036, -0.30427378, 0.2325...</td>\n",
       "      <td>0.115675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>질의응답</td>\n",
       "      <td>학교 생활을 하면서 들어가는 돈이 있나요?</td>\n",
       "      <td>저희 학교는 거의 모든 비용을 지원해줍니다. 기숙사비와 급식비 등 여행비도 다 지원...</td>\n",
       "      <td>[-0.021506025, -0.4399284, 0.12457428, -0.7633...</td>\n",
       "      <td>0.035601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>일반대화</td>\n",
       "      <td>안녕하세요</td>\n",
       "      <td>안녕하세요 부산소마고 챗봇입니다.</td>\n",
       "      <td>[-0.17859334, -0.56129384, 0.44627652, -0.1506...</td>\n",
       "      <td>0.245397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>입학홍보</td>\n",
       "      <td>학교 컷트라인은 어느정도인가요?</td>\n",
       "      <td>학교 컷트라인은매년 다릅니다. 여태까지의 컷트라인을 보고 싶으시다면 010-4074...</td>\n",
       "      <td>[-0.20965773, 0.43727145, -0.098994344, -0.421...</td>\n",
       "      <td>0.181145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     구분                       유저  \\\n",
       "0  입학홍보          부산소마고는 어떤 곳인가요?   \n",
       "1  질의응답            학교 기숙사는 어떤가요?   \n",
       "2  질의응답  학교 생활을 하면서 들어가는 돈이 있나요?   \n",
       "3  일반대화                    안녕하세요   \n",
       "4  입학홍보        학교 컷트라인은 어느정도인가요?   \n",
       "\n",
       "                                                  챗봇  \\\n",
       "0  저희 부산소프트웨어마이스터고등학교를 소개합니다. 저희 학교는 4차산업 중심 교육으로...   \n",
       "1  저희 학교 기숙사는 깨끗하고 좋습니다. 2인 1실에 각자 침대와 책상이 있구요. 기...   \n",
       "2  저희 학교는 거의 모든 비용을 지원해줍니다. 기숙사비와 급식비 등 여행비도 다 지원...   \n",
       "3                                 안녕하세요 부산소마고 챗봇입니다.   \n",
       "4  학교 컷트라인은매년 다릅니다. 여태까지의 컷트라인을 보고 싶으시다면 010-4074...   \n",
       "\n",
       "                                           embedding  distance  \n",
       "0  [-0.06551128, -0.048543196, -0.2451021, 0.4099...  0.628634  \n",
       "1  [-0.12231439, -0.43419036, -0.30427378, 0.2325...  0.115675  \n",
       "2  [-0.021506025, -0.4399284, 0.12457428, -0.7633...  0.035601  \n",
       "3  [-0.17859334, -0.56129384, 0.44627652, -0.1506...  0.245397  \n",
       "4  [-0.20965773, 0.43727145, -0.098994344, -0.421...  0.181145  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"bsg_chat.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Woongbin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\internals\\blocks.py:2323: RuntimeWarning: invalid value encountered in cast\n",
      "  values = values.astype(str)\n"
     ]
    }
   ],
   "source": [
    "df['embedding'] = df['유저'].map(lambda x : list(model.encode(x)))\n",
    "df.head()\n",
    "\n",
    "df.to_csv(\"bsg_chat.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"소마고를 소개해주세요.\"\n",
    "embedding = model.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>구분</th>\n",
       "      <th>유저</th>\n",
       "      <th>챗봇</th>\n",
       "      <th>embedding</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>입학홍보</td>\n",
       "      <td>부산소마고는 어떤 곳인가요?</td>\n",
       "      <td>저희 부산소프트웨어마이스터고등학교를 소개합니다. 저희 학교는 4차산업 중심 교육으로...</td>\n",
       "      <td>[-0.06551128, -0.048543196, -0.2451021, 0.4099...</td>\n",
       "      <td>0.628634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>질의응답</td>\n",
       "      <td>학교 기숙사는 어떤가요?</td>\n",
       "      <td>저희 학교 기숙사는 깨끗하고 좋습니다. 2인 1실에 각자 침대와 책상이 있구요. 기...</td>\n",
       "      <td>[-0.12231439, -0.43419036, -0.30427378, 0.2325...</td>\n",
       "      <td>0.115675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>질의응답</td>\n",
       "      <td>학교 생활을 하면서 들어가는 돈이 있나요?</td>\n",
       "      <td>저희 학교는 거의 모든 비용을 지원해줍니다. 기숙사비와 급식비 등 여행비도 다 지원...</td>\n",
       "      <td>[-0.021506025, -0.4399284, 0.12457428, -0.7633...</td>\n",
       "      <td>0.035601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>일반대화</td>\n",
       "      <td>안녕하세요</td>\n",
       "      <td>안녕하세요 부산소마고 챗봇입니다.</td>\n",
       "      <td>[-0.17859334, -0.56129384, 0.44627652, -0.1506...</td>\n",
       "      <td>0.245397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>입학홍보</td>\n",
       "      <td>학교 컷트라인은 어느정도인가요?</td>\n",
       "      <td>학교 컷트라인은매년 다릅니다. 여태까지의 컷트라인을 보고 싶으시다면 010-4074...</td>\n",
       "      <td>[-0.20965773, 0.43727145, -0.098994344, -0.421...</td>\n",
       "      <td>0.181145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     구분                       유저  \\\n",
       "0  입학홍보          부산소마고는 어떤 곳인가요?   \n",
       "1  질의응답            학교 기숙사는 어떤가요?   \n",
       "2  질의응답  학교 생활을 하면서 들어가는 돈이 있나요?   \n",
       "3  일반대화                    안녕하세요   \n",
       "4  입학홍보        학교 컷트라인은 어느정도인가요?   \n",
       "\n",
       "                                                  챗봇  \\\n",
       "0  저희 부산소프트웨어마이스터고등학교를 소개합니다. 저희 학교는 4차산업 중심 교육으로...   \n",
       "1  저희 학교 기숙사는 깨끗하고 좋습니다. 2인 1실에 각자 침대와 책상이 있구요. 기...   \n",
       "2  저희 학교는 거의 모든 비용을 지원해줍니다. 기숙사비와 급식비 등 여행비도 다 지원...   \n",
       "3                                 안녕하세요 부산소마고 챗봇입니다.   \n",
       "4  학교 컷트라인은매년 다릅니다. 여태까지의 컷트라인을 보고 싶으시다면 010-4074...   \n",
       "\n",
       "                                           embedding  distance  \n",
       "0  [-0.06551128, -0.048543196, -0.2451021, 0.4099...  0.628634  \n",
       "1  [-0.12231439, -0.43419036, -0.30427378, 0.2325...  0.115675  \n",
       "2  [-0.021506025, -0.4399284, 0.12457428, -0.7633...  0.035601  \n",
       "3  [-0.17859334, -0.56129384, 0.44627652, -0.1506...  0.245397  \n",
       "4  [-0.20965773, 0.43727145, -0.098994344, -0.421...  0.181145  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['distance'] = df['embedding'].map(lambda x : cosine_similarity([embedding], [x]).squeeze())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입학홍보\n",
      "부산소마고는 어떤 곳인가요?\n",
      "저희 부산소프트웨어마이스터고등학교를 소개합니다. 저희 학교는 4차산업 중심 교육으로 하는 특수 목적 고등학교 입니다. 저희는 IT기술을 배워 IT기업으로 취업하는 학교입니다. 그 외 궁금하신 질문은 010-4074-0646로 전화 주세요.\n",
      "0.6286337375640869\n",
      "질의응답\n",
      "평일에 학교 외출 가능한가요?\n",
      "특별한 사유 없이는 불가능합니다.\n",
      "-0.0451357401907444\n"
     ]
    }
   ],
   "source": [
    "answer = df.loc[df['distance'].idxmax()]\n",
    "\n",
    "print(answer['구분'])\n",
    "print(answer['유저'])\n",
    "print(answer['챗봇'])\n",
    "print(answer['distance'])\n",
    "answer = df.loc[df['distance'].idxmin()]\n",
    "\n",
    "print(answer['구분'])\n",
    "print(answer['유저'])\n",
    "print(answer['챗봇'])\n",
    "print(answer['distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c43316c98f1da13abf3ccc5c4d419348774c2c2c7227161f7eb18c2e4f98d5b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
